{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T23:18:31.812131Z",
     "iopub.status.busy": "2020-11-28T23:18:31.811091Z",
     "iopub.status.idle": "2020-11-28T23:18:31.817618Z",
     "shell.execute_reply": "2020-11-28T23:18:31.816715Z"
    },
    "papermill": {
     "duration": 0.02912,
     "end_time": "2020-11-28T23:18:31.817760",
     "exception": false,
     "start_time": "2020-11-28T23:18:31.788640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference.py\n",
    "import sys\n",
    "sys.path.append('../input/iterative-stratification/iterative-stratification-master')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-28T23:18:31.849786Z",
     "iopub.status.busy": "2020-11-28T23:18:31.848792Z",
     "iopub.status.idle": "2020-11-28T23:18:31.853059Z",
     "shell.execute_reply": "2020-11-28T23:18:31.853677Z"
    },
    "papermill": {
     "duration": 0.022259,
     "end_time": "2020-11-28T23:18:31.853817",
     "exception": false,
     "start_time": "2020-11-28T23:18:31.831558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a inference.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Dropout, BatchNormalization\n",
    "from tensorflow_addons.layers import WeightNormalization\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013174,
     "end_time": "2020-11-28T23:18:31.880475",
     "exception": false,
     "start_time": "2020-11-28T23:18:31.867301",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-28T23:18:31.910958Z",
     "iopub.status.busy": "2020-11-28T23:18:31.910004Z",
     "iopub.status.idle": "2020-11-28T23:18:31.914979Z",
     "shell.execute_reply": "2020-11-28T23:18:31.915716Z"
    },
    "papermill": {
     "duration": 0.02265,
     "end_time": "2020-11-28T23:18:31.915880",
     "exception": false,
     "start_time": "2020-11-28T23:18:31.893230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a inference.py\n",
    "\n",
    "train_features = pd.read_csv('../input/lish-moa/train_features.csv')\n",
    "train_targets = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\n",
    "test_features = pd.read_csv('../input/lish-moa/test_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.013521,
     "end_time": "2020-11-28T23:18:31.943051",
     "exception": false,
     "start_time": "2020-11-28T23:18:31.929530",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T23:18:31.974788Z",
     "iopub.status.busy": "2020-11-28T23:18:31.973837Z",
     "iopub.status.idle": "2020-11-28T23:18:31.977933Z",
     "shell.execute_reply": "2020-11-28T23:18:31.978465Z"
    },
    "papermill": {
     "duration": 0.022577,
     "end_time": "2020-11-28T23:18:31.978619",
     "exception": false,
     "start_time": "2020-11-28T23:18:31.956042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a inference.py\n",
    "\n",
    "def preprocess_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    df['cp_dose'] = df['cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "    df['cp_time'] = df['cp_time'].map({24: 0, 48: 1, 72: 2})\n",
    "    df.drop(columns=['sig_id', 'cp_type'], inplace=True)\n",
    "    return df\n",
    "    \n",
    "train_features = preprocess_features(train_features)\n",
    "test_features = preprocess_features(test_features)\n",
    "train_targets.drop(columns=['sig_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014362,
     "end_time": "2020-11-28T23:18:32.007356",
     "exception": false,
     "start_time": "2020-11-28T23:18:31.992994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T23:18:32.041883Z",
     "iopub.status.busy": "2020-11-28T23:18:32.040946Z",
     "iopub.status.idle": "2020-11-28T23:18:32.046352Z",
     "shell.execute_reply": "2020-11-28T23:18:32.045836Z"
    },
    "papermill": {
     "duration": 0.024799,
     "end_time": "2020-11-28T23:18:32.046457",
     "exception": false,
     "start_time": "2020-11-28T23:18:32.021658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a inference.py\n",
    "\n",
    "def create_training_graphs(training_history):\n",
    "    plt.figure(figsize=(16, 6))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(training_history.history['loss'])\n",
    "    plt.plot(training_history.history['val_loss'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(training_history.history['accuracy'])\n",
    "    plt.plot(training_history.history['val_accuracy'])\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T23:18:32.081956Z",
     "iopub.status.busy": "2020-11-28T23:18:32.081009Z",
     "iopub.status.idle": "2020-11-28T23:18:32.086407Z",
     "shell.execute_reply": "2020-11-28T23:18:32.085805Z"
    },
    "papermill": {
     "duration": 0.025045,
     "end_time": "2020-11-28T23:18:32.086530",
     "exception": false,
     "start_time": "2020-11-28T23:18:32.061485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a inference.py\n",
    "\n",
    "def create_model(input_size):\n",
    "    model = keras.Sequential([\n",
    "        Input(input_size),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        WeightNormalization(Dense(2048, activation=\"relu\")),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        WeightNormalization(Dense(1024, activation=\"relu\")),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        WeightNormalization(Dense(206, activation=\"sigmoid\"))\n",
    "    ])\n",
    "    \n",
    "    #optimizer=tfa.optimizers.Lookahead(tf.optimizers.Adam(), sync_period=10)\n",
    "    optimizer = tfa.optimizers.AdamW(lr = 1e-3, weight_decay = 1e-5, clipvalue = 756)\n",
    "    model.compile(loss=BinaryCrossentropy(label_smoothing=1e-15), optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014698,
     "end_time": "2020-11-28T23:18:32.116483",
     "exception": false,
     "start_time": "2020-11-28T23:18:32.101785",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T23:18:32.152005Z",
     "iopub.status.busy": "2020-11-28T23:18:32.151075Z",
     "iopub.status.idle": "2020-11-28T23:18:32.155826Z",
     "shell.execute_reply": "2020-11-28T23:18:32.156486Z"
    },
    "papermill": {
     "duration": 0.024783,
     "end_time": "2020-11-28T23:18:32.156618",
     "exception": false,
     "start_time": "2020-11-28T23:18:32.131835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a inference.py\n",
    "\n",
    "def log_loss_metric(y_true, y_pred):\n",
    "    metrics = []\n",
    "    for _target in train_targets.columns:\n",
    "        metrics.append(log_loss(y_true.loc[:, _target], y_pred.loc[:, _target].astype(float), labels = [0,1]))\n",
    "    return np.mean(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T23:18:32.192923Z",
     "iopub.status.busy": "2020-11-28T23:18:32.192004Z",
     "iopub.status.idle": "2020-11-28T23:18:32.196743Z",
     "shell.execute_reply": "2020-11-28T23:18:32.197495Z"
    },
    "papermill": {
     "duration": 0.024752,
     "end_time": "2020-11-28T23:18:32.197653",
     "exception": false,
     "start_time": "2020-11-28T23:18:32.172901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a inference.py\n",
    "\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=10, verbose=1, mode=\"auto\", baseline=None, restore_best_weights=True)\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, epsilon=1e-4, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T23:18:32.234654Z",
     "iopub.status.busy": "2020-11-28T23:18:32.233814Z",
     "iopub.status.idle": "2020-11-28T23:18:32.238534Z",
     "shell.execute_reply": "2020-11-28T23:18:32.237946Z"
    },
    "papermill": {
     "duration": 0.024887,
     "end_time": "2020-11-28T23:18:32.238634",
     "exception": false,
     "start_time": "2020-11-28T23:18:32.213747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a inference.py\n",
    "\n",
    "histories = []\n",
    "\n",
    "target_columns = train_targets.columns\n",
    "\n",
    "val_predictions = train_targets.copy()\n",
    "val_predictions.loc[:, target_columns] = 0\n",
    "\n",
    "test_predictions = pd.read_csv('../input/lish-moa/sample_submission.csv')\n",
    "test_predictions.loc[:, target_columns] = 0\n",
    "\n",
    "SEEDS = 3\n",
    "SPLITS = 5\n",
    "MAX_EPOCHS = 500\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "progress_bar = tqdm(range(SEEDS))\n",
    "for seed in progress_bar:\n",
    "    mskf = MultilabelStratifiedKFold(n_splits=SPLITS, random_state=seed, shuffle=True)\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(mskf.split(X=train_features, y=train_targets)):\n",
    "        X_train, X_val = train_features.loc[train_idx], train_features.loc[val_idx]\n",
    "        y_train, y_val = train_targets.loc[train_idx], train_targets.loc[val_idx]\n",
    "\n",
    "        model = create_model(len(train_features.columns))\n",
    "        history = model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=MAX_EPOCHS, validation_data=(X_val, y_val), callbacks=[early_stopping, reduce_lr_loss])\n",
    "        histories.append(history)\n",
    "\n",
    "        val_predictions.loc[val_idx, train_targets.columns] +=  model.predict(X_val) / SEEDS\n",
    "        test_predictions.loc[:, target_columns] += model.predict(test_features) / (SPLITS * SEEDS)\n",
    "        \n",
    "    #loss = log_loss(train_targets.loc[:, train_targets.columns], val_predictions.loc[:, train_targets.columns])\n",
    "    #progress_bar.set_description(f\"Seed: {seed} | loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T23:18:32.275744Z",
     "iopub.status.busy": "2020-11-28T23:18:32.274862Z",
     "iopub.status.idle": "2020-11-28T23:18:32.281323Z",
     "shell.execute_reply": "2020-11-28T23:18:32.280574Z"
    },
    "papermill": {
     "duration": 0.026667,
     "end_time": "2020-11-28T23:18:32.281465",
     "exception": false,
     "start_time": "2020-11-28T23:18:32.254798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a inference.py\n",
    "\n",
    "train_features1 = pd.read_csv('../input/lish-moa/train_features.csv')\n",
    "test_features1 = pd.read_csv('../input/lish-moa/test_features.csv')\n",
    "\n",
    "\n",
    "print(f'NN OOF before postprocessing: {log_loss_metric(train_targets, val_predictions):.6f}')\n",
    "val_predictions.loc[train_features1['cp_type'] == 'ctl_vehicle', train_targets.columns] = 0\n",
    "test_predictions.loc[test_features1['cp_type'] == 'ctl_vehicle', train_targets.columns] = 0\n",
    "print(f'NN OOF after postprocessing: {log_loss_metric(train_targets, val_predictions):.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.018074,
     "end_time": "2020-11-28T23:18:32.317085",
     "exception": false,
     "start_time": "2020-11-28T23:18:32.299011",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T23:18:32.355715Z",
     "iopub.status.busy": "2020-11-28T23:18:32.354722Z",
     "iopub.status.idle": "2020-11-28T23:18:32.360141Z",
     "shell.execute_reply": "2020-11-28T23:18:32.359572Z"
    },
    "papermill": {
     "duration": 0.026084,
     "end_time": "2020-11-28T23:18:32.360254",
     "exception": false,
     "start_time": "2020-11-28T23:18:32.334170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a inference.py\n",
    "val_predictions.to_csv('val-submission.csv', index=False)\n",
    "test_predictions.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-28T23:18:32.402055Z",
     "iopub.status.busy": "2020-11-28T23:18:32.401183Z",
     "iopub.status.idle": "2020-11-28T23:41:52.292755Z",
     "shell.execute_reply": "2020-11-28T23:41:52.292138Z"
    },
    "papermill": {
     "duration": 1399.914677,
     "end_time": "2020-11-28T23:41:52.292873",
     "exception": false,
     "start_time": "2020-11-28T23:18:32.378196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-28 23:18:36.037951: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\r\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:68: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.3.0 (nightly versions are not supported). \r\n",
      " The versions of TensorFlow you are currently using is 2.3.1 and is not supported. \r\n",
      "Some things might work, some things might not.\r\n",
      "If you were to encounter a bug, do not file an issue.\r\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \r\n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\r\n",
      "https://github.com/tensorflow/addons\r\n",
      "  UserWarning,\r\n",
      "2.4.0\r\n",
      "2.3.1\r\n",
      "  0%|                                                     | 0/3 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass shuffle=True, random_state=0 as keyword args. From version 0.25 passing these as positional arguments will result in an error\r\n",
      "  FutureWarning)\r\n",
      "2020-11-28 23:18:49.427801: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\r\n",
      "2020-11-28 23:18:49.781377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2020-11-28 23:18:49.782152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\n",
      "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\r\n",
      "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\r\n",
      "2020-11-28 23:18:49.782264: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\r\n",
      "2020-11-28 23:18:49.894145: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n",
      "2020-11-28 23:18:49.960650: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n",
      "2020-11-28 23:18:49.974991: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n",
      "2020-11-28 23:18:50.087002: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n",
      "2020-11-28 23:18:50.099454: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n",
      "2020-11-28 23:18:50.291001: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n",
      "2020-11-28 23:18:50.291539: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2020-11-28 23:18:50.292601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2020-11-28 23:18:50.293330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n",
      "2020-11-28 23:18:50.293708: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX512F\r\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n",
      "2020-11-28 23:18:50.317801: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2000179999 Hz\r\n",
      "2020-11-28 23:18:50.318094: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5624639876d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n",
      "2020-11-28 23:18:50.318230: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n",
      "2020-11-28 23:18:50.320013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2020-11-28 23:18:50.320827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\n",
      "pciBusID: 0000:00:04.0 name: Tesla P100-PCIE-16GB computeCapability: 6.0\r\n",
      "coreClock: 1.3285GHz coreCount: 56 deviceMemorySize: 15.90GiB deviceMemoryBandwidth: 681.88GiB/s\r\n",
      "2020-11-28 23:18:50.320924: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\r\n",
      "2020-11-28 23:18:50.320991: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n",
      "2020-11-28 23:18:50.321041: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n",
      "2020-11-28 23:18:50.321076: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n",
      "2020-11-28 23:18:50.321122: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n",
      "2020-11-28 23:18:50.321159: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n",
      "2020-11-28 23:18:50.321223: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n",
      "2020-11-28 23:18:50.321347: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2020-11-28 23:18:50.322181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2020-11-28 23:18:50.322879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n",
      "2020-11-28 23:18:50.324590: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.2\r\n",
      "2020-11-28 23:18:51.765797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n",
      "2020-11-28 23:18:51.765860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \r\n",
      "2020-11-28 23:18:51.765889: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \r\n",
      "2020-11-28 23:18:51.769096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2020-11-28 23:18:51.769997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2020-11-28 23:18:51.770794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n",
      "2020-11-28 23:18:51.771515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14975 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\r\n",
      "2020-11-28 23:18:51.778780: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562472aebc80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n",
      "2020-11-28 23:18:51.778822: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\r\n",
      "Epoch 1/500\r\n",
      "2020-11-28 23:18:55.736613: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n",
      "298/298 [==============================] - 3s 11ms/step - loss: 0.2438 - val_loss: 0.0251\r\n",
      "Epoch 2/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0226 - val_loss: 0.0196\r\n",
      "Epoch 3/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0194 - val_loss: 0.0180\r\n",
      "Epoch 4/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0182 - val_loss: 0.0171\r\n",
      "Epoch 5/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0175 - val_loss: 0.0168\r\n",
      "Epoch 6/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0170 - val_loss: 0.0165\r\n",
      "Epoch 7/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0164 - val_loss: 0.0162\r\n",
      "Epoch 8/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0161 - val_loss: 0.0159\r\n",
      "Epoch 9/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0157 - val_loss: 0.0158\r\n",
      "Epoch 10/500\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.0153 - val_loss: 0.0157\r\n",
      "Epoch 11/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0149 - val_loss: 0.0156\r\n",
      "Epoch 12/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0145 - val_loss: 0.0156\r\n",
      "Epoch 13/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0142 - val_loss: 0.0155\r\n",
      "Epoch 14/500\r\n",
      "296/298 [============================>.] - ETA: 0s - loss: 0.0139\r\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0139 - val_loss: 0.0155\r\n",
      "Epoch 15/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0129 - val_loss: 0.0152\r\n",
      "Epoch 16/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0127 - val_loss: 0.0151\r\n",
      "Epoch 17/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0124 - val_loss: 0.0151\r\n",
      "Epoch 18/500\r\n",
      "296/298 [============================>.] - ETA: 0s - loss: 0.0123\r\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0123 - val_loss: 0.0151\r\n",
      "Epoch 19/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0121 - val_loss: 0.0151\r\n",
      "Epoch 20/500\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.0121 - val_loss: 0.0151\r\n",
      "Epoch 21/500\r\n",
      "295/298 [============================>.] - ETA: 0s - loss: 0.0121\r\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0121 - val_loss: 0.0151\r\n",
      "Epoch 22/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0121 - val_loss: 0.0151\r\n",
      "Epoch 23/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0121 - val_loss: 0.0151\r\n",
      "Epoch 24/500\r\n",
      "298/298 [==============================] - ETA: 0s - loss: 0.0121\r\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0121 - val_loss: 0.0151\r\n",
      "Epoch 25/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0121 - val_loss: 0.0151\r\n",
      "Epoch 26/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0122 - val_loss: 0.0151\r\n",
      "Epoch 27/500\r\n",
      "297/298 [============================>.] - ETA: 0s - loss: 0.0122\r\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0122 - val_loss: 0.0151\r\n",
      "Epoch 28/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0122 - val_loss: 0.0151\r\n",
      "Epoch 29/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0123 - val_loss: 0.0151\r\n",
      "Epoch 30/500\r\n",
      "292/298 [============================>.] - ETA: 0s - loss: 0.0123Restoring model weights from the end of the best epoch.\r\n",
      "\r\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0123 - val_loss: 0.0151\r\n",
      "Epoch 00030: early stopping\r\n",
      "Epoch 1/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.2448 - val_loss: 0.0256\r\n",
      "Epoch 2/500\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.0230 - val_loss: 0.0195\r\n",
      "Epoch 3/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0195 - val_loss: 0.0180\r\n",
      "Epoch 4/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0184 - val_loss: 0.0174\r\n",
      "Epoch 5/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0176 - val_loss: 0.0168\r\n",
      "Epoch 6/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0170 - val_loss: 0.0164\r\n",
      "Epoch 7/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0166 - val_loss: 0.0161\r\n",
      "Epoch 8/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0161 - val_loss: 0.0159\r\n",
      "Epoch 9/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0157 - val_loss: 0.0159\r\n",
      "Epoch 10/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0154 - val_loss: 0.0158\r\n",
      "Epoch 11/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0151 - val_loss: 0.0155\r\n",
      "Epoch 12/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0146 - val_loss: 0.0155\r\n",
      "Epoch 13/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0142 - val_loss: 0.0154\r\n",
      "Epoch 14/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0138 - val_loss: 0.0153\r\n",
      "Epoch 15/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0136 - val_loss: 0.0156\r\n",
      "Epoch 16/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0132 - val_loss: 0.0153\r\n",
      "Epoch 17/500\r\n",
      "297/298 [============================>.] - ETA: 0s - loss: 0.0127\r\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0127 - val_loss: 0.0154\r\n",
      "Epoch 18/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0116 - val_loss: 0.0151\r\n",
      "Epoch 19/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0114 - val_loss: 0.0151\r\n",
      "Epoch 20/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0111 - val_loss: 0.0151\r\n",
      "Epoch 21/500\r\n",
      "294/298 [============================>.] - ETA: 0s - loss: 0.0110\r\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0110 - val_loss: 0.0151\r\n",
      "Epoch 22/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0107 - val_loss: 0.0151\r\n",
      "Epoch 23/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0107 - val_loss: 0.0151\r\n",
      "Epoch 24/500\r\n",
      "294/298 [============================>.] - ETA: 0s - loss: 0.0107\r\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0107 - val_loss: 0.0151\r\n",
      "Epoch 25/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0107 - val_loss: 0.0150\r\n",
      "Epoch 26/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0107 - val_loss: 0.0150\r\n",
      "Epoch 27/500\r\n",
      "292/298 [============================>.] - ETA: 0s - loss: 0.0107\r\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0107 - val_loss: 0.0150\r\n",
      "Epoch 28/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0108 - val_loss: 0.0150\r\n",
      "Epoch 29/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0108 - val_loss: 0.0150\r\n",
      "Epoch 30/500\r\n",
      "297/298 [============================>.] - ETA: 0s - loss: 0.0108\r\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0108 - val_loss: 0.0150\r\n",
      "Epoch 31/500\r\n",
      "298/298 [==============================] - 3s 11ms/step - loss: 0.0108 - val_loss: 0.0150\r\n",
      "Epoch 32/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0109 - val_loss: 0.0150\r\n",
      "Epoch 33/500\r\n",
      "293/298 [============================>.] - ETA: 0s - loss: 0.0109\r\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0109 - val_loss: 0.0150\r\n",
      "Epoch 34/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0110 - val_loss: 0.0150\r\n",
      "Epoch 35/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0110 - val_loss: 0.0150\r\n",
      "Epoch 36/500\r\n",
      "294/298 [============================>.] - ETA: 0s - loss: 0.0110\r\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0110 - val_loss: 0.0151\r\n",
      "Epoch 37/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0111 - val_loss: 0.0151\r\n",
      "Epoch 38/500\r\n",
      "293/298 [============================>.] - ETA: 0s - loss: 0.0111Restoring model weights from the end of the best epoch.\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0111 - val_loss: 0.0151\r\n",
      "Epoch 00038: early stopping\r\n",
      "Epoch 1/500\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.2466 - val_loss: 0.0246\r\n",
      "Epoch 2/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0225 - val_loss: 0.0191\r\n",
      "Epoch 3/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0195 - val_loss: 0.0179\r\n",
      "Epoch 4/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0183 - val_loss: 0.0173\r\n",
      "Epoch 5/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0175 - val_loss: 0.0166\r\n",
      "Epoch 6/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0170 - val_loss: 0.0162\r\n",
      "Epoch 7/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0165 - val_loss: 0.0161\r\n",
      "Epoch 8/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0160 - val_loss: 0.0159\r\n",
      "Epoch 9/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0158 - val_loss: 0.0158\r\n",
      "Epoch 10/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0153 - val_loss: 0.0156\r\n",
      "Epoch 11/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0149 - val_loss: 0.0155\r\n",
      "Epoch 12/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0145 - val_loss: 0.0154\r\n",
      "Epoch 13/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0142 - val_loss: 0.0152\r\n",
      "Epoch 14/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0138 - val_loss: 0.0153\r\n",
      "Epoch 15/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0135 - val_loss: 0.0153\r\n",
      "Epoch 16/500\r\n",
      "293/298 [============================>.] - ETA: 0s - loss: 0.0131\r\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0131 - val_loss: 0.0153\r\n",
      "Epoch 17/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0120 - val_loss: 0.0151\r\n",
      "Epoch 18/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0117 - val_loss: 0.0151\r\n",
      "Epoch 19/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0115 - val_loss: 0.0150\r\n",
      "Epoch 20/500\r\n",
      "290/298 [============================>.] - ETA: 0s - loss: 0.0114\r\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0114 - val_loss: 0.0150\r\n",
      "Epoch 21/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0112 - val_loss: 0.0150\r\n",
      "Epoch 22/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0112 - val_loss: 0.0150\r\n",
      "Epoch 23/500\r\n",
      "291/298 [============================>.] - ETA: 0s - loss: 0.0112\r\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0112 - val_loss: 0.0150\r\n",
      "Epoch 24/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0111 - val_loss: 0.0150\r\n",
      "Epoch 25/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0112 - val_loss: 0.0150\r\n",
      "Epoch 26/500\r\n",
      "296/298 [============================>.] - ETA: 0s - loss: 0.0112\r\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0112 - val_loss: 0.0150\r\n",
      "Epoch 27/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0112 - val_loss: 0.0150\r\n",
      "Epoch 28/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0112 - val_loss: 0.0150\r\n",
      "Epoch 29/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0113 - val_loss: 0.0150\r\n",
      "Epoch 30/500\r\n",
      "293/298 [============================>.] - ETA: 0s - loss: 0.0113\r\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0113 - val_loss: 0.0150\r\n",
      "Epoch 31/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0113 - val_loss: 0.0150\r\n",
      "Epoch 32/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0114 - val_loss: 0.0150\r\n",
      "Epoch 33/500\r\n",
      "295/298 [============================>.] - ETA: 0s - loss: 0.0114\r\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0114 - val_loss: 0.0150\r\n",
      "Epoch 34/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0114 - val_loss: 0.0150\r\n",
      "Epoch 35/500\r\n",
      "298/298 [==============================] - 3s 8ms/step - loss: 0.0115 - val_loss: 0.0151\r\n",
      "Epoch 36/500\r\n",
      "294/298 [============================>.] - ETA: 0s - loss: 0.0115\r\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0115 - val_loss: 0.0151\r\n",
      "Epoch 37/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0115 - val_loss: 0.0151\r\n",
      "Epoch 38/500\r\n",
      "291/298 [============================>.] - ETA: 0s - loss: 0.0116Restoring model weights from the end of the best epoch.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0117 - val_loss: 0.0151\r\n",
      "Epoch 00038: early stopping\r\n",
      "Epoch 1/500\r\n",
      "298/298 [==============================] - 4s 13ms/step - loss: 0.2472 - val_loss: 0.0250\r\n",
      "Epoch 2/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0224 - val_loss: 0.0192\r\n",
      "Epoch 3/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0196 - val_loss: 0.0180\r\n",
      "Epoch 4/500\r\n",
      "298/298 [==============================] - 3s 8ms/step - loss: 0.0183 - val_loss: 0.0172\r\n",
      "Epoch 5/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0176 - val_loss: 0.0168\r\n",
      "Epoch 6/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0170 - val_loss: 0.0165\r\n",
      "Epoch 7/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0164 - val_loss: 0.0162\r\n",
      "Epoch 8/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0161 - val_loss: 0.0159\r\n",
      "Epoch 9/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0157 - val_loss: 0.0160\r\n",
      "Epoch 10/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0153 - val_loss: 0.0155\r\n",
      "Epoch 11/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0150 - val_loss: 0.0155\r\n",
      "Epoch 12/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0145 - val_loss: 0.0154\r\n",
      "Epoch 13/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0141 - val_loss: 0.0153\r\n",
      "Epoch 14/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0138 - val_loss: 0.0155\r\n",
      "Epoch 15/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0134 - val_loss: 0.0152\r\n",
      "Epoch 16/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0130 - val_loss: 0.0153\r\n",
      "Epoch 17/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0127 - val_loss: 0.0153\r\n",
      "Epoch 18/500\r\n",
      "296/298 [============================>.] - ETA: 0s - loss: 0.0122\r\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0122 - val_loss: 0.0153\r\n",
      "Epoch 19/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0112 - val_loss: 0.0151\r\n",
      "Epoch 20/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0108 - val_loss: 0.0151\r\n",
      "Epoch 21/500\r\n",
      "293/298 [============================>.] - ETA: 0s - loss: 0.0106\r\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0106 - val_loss: 0.0151\r\n",
      "Epoch 22/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0104 - val_loss: 0.0151\r\n",
      "Epoch 23/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0104 - val_loss: 0.0151\r\n",
      "Epoch 24/500\r\n",
      "298/298 [==============================] - ETA: 0s - loss: 0.0104\r\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0104 - val_loss: 0.0151\r\n",
      "Epoch 25/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0104 - val_loss: 0.0151\r\n",
      "Epoch 26/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0104 - val_loss: 0.0151\r\n",
      "Epoch 27/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0103 - val_loss: 0.0151\r\n",
      "Epoch 28/500\r\n",
      "296/298 [============================>.] - ETA: 0s - loss: 0.0104\r\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0104 - val_loss: 0.0151\r\n",
      "Epoch 29/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0104 - val_loss: 0.0151\r\n",
      "Epoch 30/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0105 - val_loss: 0.0151\r\n",
      "Epoch 31/500\r\n",
      "297/298 [============================>.] - ETA: 0s - loss: 0.0104\r\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\r\n",
      "298/298 [==============================] - 3s 11ms/step - loss: 0.0105 - val_loss: 0.0151\r\n",
      "Epoch 32/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0105 - val_loss: 0.0151\r\n",
      "Epoch 33/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0105 - val_loss: 0.0151\r\n",
      "Epoch 34/500\r\n",
      "298/298 [==============================] - ETA: 0s - loss: 0.0106\r\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0106 - val_loss: 0.0151\r\n",
      "Epoch 35/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0106 - val_loss: 0.0151\r\n",
      "Epoch 36/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0107 - val_loss: 0.0151\r\n",
      "Epoch 37/500\r\n",
      "298/298 [==============================] - ETA: 0s - loss: 0.0107\r\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0107 - val_loss: 0.0151\r\n",
      "Epoch 38/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0108 - val_loss: 0.0151\r\n",
      "Epoch 39/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0108 - val_loss: 0.0151\r\n",
      "Epoch 40/500\r\n",
      "290/298 [============================>.] - ETA: 0s - loss: 0.0108\r\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0108 - val_loss: 0.0151\r\n",
      "Epoch 41/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0109 - val_loss: 0.0152\r\n",
      "Epoch 42/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0109 - val_loss: 0.0152\r\n",
      "Epoch 43/500\r\n",
      "293/298 [============================>.] - ETA: 0s - loss: 0.0110Restoring model weights from the end of the best epoch.\r\n",
      "\r\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-12.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0110 - val_loss: 0.0152\r\n",
      "Epoch 00043: early stopping\r\n",
      "Epoch 1/500\r\n",
      "298/298 [==============================] - 4s 13ms/step - loss: 0.2435 - val_loss: 0.0244\r\n",
      "Epoch 2/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0223 - val_loss: 0.0191\r\n",
      "Epoch 3/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0193 - val_loss: 0.0178\r\n",
      "Epoch 4/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0182 - val_loss: 0.0171\r\n",
      "Epoch 5/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0175 - val_loss: 0.0166\r\n",
      "Epoch 6/500\r\n",
      "298/298 [==============================] - 3s 8ms/step - loss: 0.0169 - val_loss: 0.0163\r\n",
      "Epoch 7/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0164 - val_loss: 0.0160\r\n",
      "Epoch 8/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0161 - val_loss: 0.0158\r\n",
      "Epoch 9/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0157 - val_loss: 0.0158\r\n",
      "Epoch 10/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0153 - val_loss: 0.0156\r\n",
      "Epoch 11/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0149 - val_loss: 0.0156\r\n",
      "Epoch 12/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0145 - val_loss: 0.0156\r\n",
      "Epoch 13/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0142 - val_loss: 0.0155\r\n",
      "Epoch 14/500\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.0138 - val_loss: 0.0153\r\n",
      "Epoch 15/500\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.0134 - val_loss: 0.0153\r\n",
      "Epoch 16/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0130 - val_loss: 0.0154\r\n",
      "Epoch 17/500\r\n",
      "290/298 [============================>.] - ETA: 0s - loss: 0.0126\r\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0126 - val_loss: 0.0153\r\n",
      "Epoch 18/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0116 - val_loss: 0.0152\r\n",
      "Epoch 19/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0112 - val_loss: 0.0152\r\n",
      "Epoch 20/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0110 - val_loss: 0.0152\r\n",
      "Epoch 21/500\r\n",
      "293/298 [============================>.] - ETA: 0s - loss: 0.0108\r\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0108 - val_loss: 0.0152\r\n",
      "Epoch 22/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0106 - val_loss: 0.0152\r\n",
      "Epoch 23/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0105 - val_loss: 0.0152\r\n",
      "Epoch 24/500\r\n",
      "293/298 [============================>.] - ETA: 0s - loss: 0.0106\r\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0106 - val_loss: 0.0152\r\n",
      "Epoch 25/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0106 - val_loss: 0.0152\r\n",
      "Epoch 26/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0106 - val_loss: 0.0151\r\n",
      "Epoch 27/500\r\n",
      "293/298 [============================>.] - ETA: 0s - loss: 0.0106\r\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0106 - val_loss: 0.0151\r\n",
      "Epoch 28/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0106 - val_loss: 0.0151\r\n",
      "Epoch 29/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0106 - val_loss: 0.0151\r\n",
      "Epoch 30/500\r\n",
      "294/298 [============================>.] - ETA: 0s - loss: 0.0107\r\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0107 - val_loss: 0.0151\r\n",
      "Epoch 31/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0107 - val_loss: 0.0151\r\n",
      "Epoch 32/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0107 - val_loss: 0.0151\r\n",
      "Epoch 33/500\r\n",
      "292/298 [============================>.] - ETA: 0s - loss: 0.0107\r\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0107 - val_loss: 0.0151\r\n",
      "Epoch 34/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0108 - val_loss: 0.0152\r\n",
      "Epoch 35/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0108 - val_loss: 0.0152\r\n",
      "Epoch 36/500\r\n",
      "291/298 [============================>.] - ETA: 0s - loss: 0.0109\r\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0109 - val_loss: 0.0152\r\n",
      "Epoch 37/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0109 - val_loss: 0.0152\r\n",
      "Epoch 38/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0110 - val_loss: 0.0152\r\n",
      "Epoch 39/500\r\n",
      "298/298 [==============================] - ETA: 0s - loss: 0.0110\r\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0110 - val_loss: 0.0152\r\n",
      "Epoch 40/500\r\n",
      "296/298 [============================>.] - ETA: 0s - loss: 0.0111Restoring model weights from the end of the best epoch.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0111 - val_loss: 0.0152\r\n",
      "Epoch 00040: early stopping\r\n",
      " 33%|██████████████▋                             | 1/3 [07:38<15:17, 458.53s/it]/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass shuffle=True, random_state=1 as keyword args. From version 0.25 passing these as positional arguments will result in an error\r\n",
      "  FutureWarning)\r\n",
      "Epoch 1/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.2458 - val_loss: 0.0266\r\n",
      "Epoch 2/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0223 - val_loss: 0.0192\r\n",
      "Epoch 3/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0193 - val_loss: 0.0179\r\n",
      "Epoch 4/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0183 - val_loss: 0.0174\r\n",
      "Epoch 5/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0176 - val_loss: 0.0169\r\n",
      "Epoch 6/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0170 - val_loss: 0.0164\r\n",
      "Epoch 7/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0165 - val_loss: 0.0162\r\n",
      "Epoch 8/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0161 - val_loss: 0.0160\r\n",
      "Epoch 9/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0157 - val_loss: 0.0158\r\n",
      "Epoch 10/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0153 - val_loss: 0.0156\r\n",
      "Epoch 11/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0149 - val_loss: 0.0155\r\n",
      "Epoch 12/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0146 - val_loss: 0.0154\r\n",
      "Epoch 13/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0143 - val_loss: 0.0154\r\n",
      "Epoch 14/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0139 - val_loss: 0.0154\r\n",
      "Epoch 15/500\r\n",
      "296/298 [============================>.] - ETA: 0s - loss: 0.0136\r\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0136 - val_loss: 0.0153\r\n",
      "Epoch 16/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0126 - val_loss: 0.0151\r\n",
      "Epoch 17/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0123 - val_loss: 0.0151\r\n",
      "Epoch 18/500\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.0121 - val_loss: 0.0151\r\n",
      "Epoch 19/500\r\n",
      "295/298 [============================>.] - ETA: 0s - loss: 0.0120\r\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.0120 - val_loss: 0.0150\r\n",
      "Epoch 20/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0118 - val_loss: 0.0150\r\n",
      "Epoch 21/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0117 - val_loss: 0.0150\r\n",
      "Epoch 22/500\r\n",
      "294/298 [============================>.] - ETA: 0s - loss: 0.0117\r\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0117 - val_loss: 0.0150\r\n",
      "Epoch 23/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0117 - val_loss: 0.0150\r\n",
      "Epoch 24/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0117 - val_loss: 0.0150\r\n",
      "Epoch 25/500\r\n",
      "295/298 [============================>.] - ETA: 0s - loss: 0.0117\r\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0117 - val_loss: 0.0150\r\n",
      "Epoch 26/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0117 - val_loss: 0.0150\r\n",
      "Epoch 27/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0118 - val_loss: 0.0150\r\n",
      "Epoch 28/500\r\n",
      "291/298 [============================>.] - ETA: 0s - loss: 0.0119\r\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0119 - val_loss: 0.0150\r\n",
      "Epoch 29/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0119 - val_loss: 0.0150\r\n",
      "Epoch 30/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0119 - val_loss: 0.0151\r\n",
      "Epoch 31/500\r\n",
      "294/298 [============================>.] - ETA: 0s - loss: 0.0119\r\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0119 - val_loss: 0.0151\r\n",
      "Epoch 32/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0119 - val_loss: 0.0151\r\n",
      "Epoch 33/500\r\n",
      "295/298 [============================>.] - ETA: 0s - loss: 0.0121Restoring model weights from the end of the best epoch.\r\n",
      "298/298 [==============================] - 4s 12ms/step - loss: 0.0121 - val_loss: 0.0151\r\n",
      "Epoch 00033: early stopping\r\n",
      "Epoch 1/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.2468 - val_loss: 0.0247\r\n",
      "Epoch 2/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0227 - val_loss: 0.0198\r\n",
      "Epoch 3/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0195 - val_loss: 0.0181\r\n",
      "Epoch 4/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0184 - val_loss: 0.0171\r\n",
      "Epoch 5/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0176 - val_loss: 0.0166\r\n",
      "Epoch 6/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0170 - val_loss: 0.0162\r\n",
      "Epoch 7/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0165 - val_loss: 0.0160\r\n",
      "Epoch 8/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0161 - val_loss: 0.0158\r\n",
      "Epoch 9/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0157 - val_loss: 0.0157\r\n",
      "Epoch 10/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0153 - val_loss: 0.0155\r\n",
      "Epoch 11/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0150 - val_loss: 0.0154\r\n",
      "Epoch 12/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0146 - val_loss: 0.0154\r\n",
      "Epoch 13/500\r\n",
      "298/298 [==============================] - 4s 13ms/step - loss: 0.0143 - val_loss: 0.0154\r\n",
      "Epoch 14/500\r\n",
      "298/298 [==============================] - 3s 12ms/step - loss: 0.0139 - val_loss: 0.0153\r\n",
      "Epoch 15/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0136 - val_loss: 0.0153\r\n",
      "Epoch 16/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0132 - val_loss: 0.0153\r\n",
      "Epoch 17/500\r\n",
      "297/298 [============================>.] - ETA: 0s - loss: 0.0128\r\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0128 - val_loss: 0.0153\r\n",
      "Epoch 18/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0118 - val_loss: 0.0151\r\n",
      "Epoch 19/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0114 - val_loss: 0.0151\r\n",
      "Epoch 20/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0112 - val_loss: 0.0151\r\n",
      "Epoch 21/500\r\n",
      "295/298 [============================>.] - ETA: 0s - loss: 0.0110\r\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0110 - val_loss: 0.0151\r\n",
      "Epoch 22/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0108 - val_loss: 0.0151\r\n",
      "Epoch 23/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0108 - val_loss: 0.0151\r\n",
      "Epoch 24/500\r\n",
      "298/298 [==============================] - ETA: 0s - loss: 0.0108\r\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0108 - val_loss: 0.0151\r\n",
      "Epoch 25/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0107 - val_loss: 0.0151\r\n",
      "Epoch 26/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0108 - val_loss: 0.0151\r\n",
      "Epoch 27/500\r\n",
      "295/298 [============================>.] - ETA: 0s - loss: 0.0108\r\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0108 - val_loss: 0.0151\r\n",
      "Epoch 28/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0108 - val_loss: 0.0151\r\n",
      "Epoch 29/500\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.0108 - val_loss: 0.0151\r\n",
      "Epoch 30/500\r\n",
      "298/298 [==============================] - ETA: 0s - loss: 0.0109\r\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.0109 - val_loss: 0.0151\r\n",
      "Epoch 31/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0109 - val_loss: 0.0151\r\n",
      "Epoch 32/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0110 - val_loss: 0.0151\r\n",
      "Epoch 33/500\r\n",
      "294/298 [============================>.] - ETA: 0s - loss: 0.0110\r\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0110 - val_loss: 0.0151\r\n",
      "Epoch 34/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0110 - val_loss: 0.0151\r\n",
      "Epoch 35/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0111 - val_loss: 0.0151\r\n",
      "Epoch 36/500\r\n",
      "294/298 [============================>.] - ETA: 0s - loss: 0.0111\r\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0111 - val_loss: 0.0151\r\n",
      "Epoch 37/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0112 - val_loss: 0.0151\r\n",
      "Epoch 38/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0112 - val_loss: 0.0151\r\n",
      "Epoch 39/500\r\n",
      "297/298 [============================>.] - ETA: 0s - loss: 0.0112Restoring model weights from the end of the best epoch.\r\n",
      "\r\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0112 - val_loss: 0.0152\r\n",
      "Epoch 00039: early stopping\r\n",
      "Epoch 1/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.2476 - val_loss: 0.0242\r\n",
      "Epoch 2/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0224 - val_loss: 0.0191\r\n",
      "Epoch 3/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0192 - val_loss: 0.0178\r\n",
      "Epoch 4/500\r\n",
      "298/298 [==============================] - 3s 11ms/step - loss: 0.0182 - val_loss: 0.0171\r\n",
      "Epoch 5/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0174 - val_loss: 0.0166\r\n",
      "Epoch 6/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0169 - val_loss: 0.0163\r\n",
      "Epoch 7/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0163 - val_loss: 0.0161\r\n",
      "Epoch 8/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0160 - val_loss: 0.0159\r\n",
      "Epoch 9/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0156 - val_loss: 0.0157\r\n",
      "Epoch 10/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0153 - val_loss: 0.0156\r\n",
      "Epoch 11/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0149 - val_loss: 0.0155\r\n",
      "Epoch 12/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0145 - val_loss: 0.0154\r\n",
      "Epoch 13/500\r\n",
      "298/298 [==============================] - 3s 8ms/step - loss: 0.0142 - val_loss: 0.0153\r\n",
      "Epoch 14/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0137 - val_loss: 0.0154\r\n",
      "Epoch 15/500\r\n",
      "295/298 [============================>.] - ETA: 0s - loss: 0.0134\r\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0134 - val_loss: 0.0153\r\n",
      "Epoch 16/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0124 - val_loss: 0.0151\r\n",
      "Epoch 17/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0122 - val_loss: 0.0150\r\n",
      "Epoch 18/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0119 - val_loss: 0.0150\r\n",
      "Epoch 19/500\r\n",
      "297/298 [============================>.] - ETA: 0s - loss: 0.0117\r\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\r\n",
      "298/298 [==============================] - 3s 8ms/step - loss: 0.0117 - val_loss: 0.0150\r\n",
      "Epoch 20/500\r\n",
      "298/298 [==============================] - 3s 11ms/step - loss: 0.0115 - val_loss: 0.0150\r\n",
      "Epoch 21/500\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.0115 - val_loss: 0.0150\r\n",
      "Epoch 22/500\r\n",
      "294/298 [============================>.] - ETA: 0s - loss: 0.0115\r\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0115 - val_loss: 0.0150\r\n",
      "Epoch 23/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0116 - val_loss: 0.0150\r\n",
      "Epoch 24/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0116 - val_loss: 0.0150\r\n",
      "Epoch 25/500\r\n",
      "297/298 [============================>.] - ETA: 0s - loss: 0.0115\r\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0115 - val_loss: 0.0150\r\n",
      "Epoch 26/500\r\n",
      "298/298 [==============================] - 3s 8ms/step - loss: 0.0116 - val_loss: 0.0150\r\n",
      "Epoch 27/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0116 - val_loss: 0.0150\r\n",
      "Epoch 28/500\r\n",
      "297/298 [============================>.] - ETA: 0s - loss: 0.0116\r\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0116 - val_loss: 0.0150\r\n",
      "Epoch 29/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0117 - val_loss: 0.0150\r\n",
      "Epoch 30/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0117 - val_loss: 0.0150\r\n",
      "Epoch 31/500\r\n",
      "296/298 [============================>.] - ETA: 0s - loss: 0.0117\r\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0117 - val_loss: 0.0150\r\n",
      "Epoch 32/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0118 - val_loss: 0.0151\r\n",
      "Epoch 33/500\r\n",
      "290/298 [============================>.] - ETA: 0s - loss: 0.0119Restoring model weights from the end of the best epoch.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0118 - val_loss: 0.0151\r\n",
      "Epoch 00033: early stopping\r\n",
      "Epoch 1/500\r\n",
      "298/298 [==============================] - 4s 13ms/step - loss: 0.2446 - val_loss: 0.0269\r\n",
      "Epoch 2/500\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.0225 - val_loss: 0.0192\r\n",
      "Epoch 3/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0194 - val_loss: 0.0181\r\n",
      "Epoch 4/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0183 - val_loss: 0.0172\r\n",
      "Epoch 5/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0175 - val_loss: 0.0167\r\n",
      "Epoch 6/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0170 - val_loss: 0.0167\r\n",
      "Epoch 7/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0165 - val_loss: 0.0162\r\n",
      "Epoch 8/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0161 - val_loss: 0.0161\r\n",
      "Epoch 9/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0158 - val_loss: 0.0160\r\n",
      "Epoch 10/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0154 - val_loss: 0.0158\r\n",
      "Epoch 11/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0151 - val_loss: 0.0157\r\n",
      "Epoch 12/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0148 - val_loss: 0.0155\r\n",
      "Epoch 13/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0142 - val_loss: 0.0155\r\n",
      "Epoch 14/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0139 - val_loss: 0.0157\r\n",
      "Epoch 15/500\r\n",
      "293/298 [============================>.] - ETA: 0s - loss: 0.0135\r\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0135 - val_loss: 0.0156\r\n",
      "Epoch 16/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0126 - val_loss: 0.0152\r\n",
      "Epoch 17/500\r\n",
      "298/298 [==============================] - 3s 11ms/step - loss: 0.0123 - val_loss: 0.0152\r\n",
      "Epoch 18/500\r\n",
      "298/298 [==============================] - 3s 11ms/step - loss: 0.0122 - val_loss: 0.0152\r\n",
      "Epoch 19/500\r\n",
      "292/298 [============================>.] - ETA: 0s - loss: 0.0120\r\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0120 - val_loss: 0.0152\r\n",
      "Epoch 20/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0118 - val_loss: 0.0152\r\n",
      "Epoch 21/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0118 - val_loss: 0.0152\r\n",
      "Epoch 22/500\r\n",
      "292/298 [============================>.] - ETA: 0s - loss: 0.0118\r\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0118 - val_loss: 0.0152\r\n",
      "Epoch 23/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0118 - val_loss: 0.0151\r\n",
      "Epoch 24/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0118 - val_loss: 0.0151\r\n",
      "Epoch 25/500\r\n",
      "295/298 [============================>.] - ETA: 0s - loss: 0.0118\r\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0118 - val_loss: 0.0152\r\n",
      "Epoch 26/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0119 - val_loss: 0.0152\r\n",
      "Epoch 27/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0119 - val_loss: 0.0152\r\n",
      "Epoch 28/500\r\n",
      "294/298 [============================>.] - ETA: 0s - loss: 0.0119\r\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0119 - val_loss: 0.0152\r\n",
      "Epoch 29/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0119 - val_loss: 0.0152\r\n",
      "Epoch 30/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0119 - val_loss: 0.0152\r\n",
      "Epoch 31/500\r\n",
      "290/298 [============================>.] - ETA: 0s - loss: 0.0120\r\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0120 - val_loss: 0.0152\r\n",
      "Epoch 32/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0120 - val_loss: 0.0152\r\n",
      "Epoch 33/500\r\n",
      "298/298 [==============================] - ETA: 0s - loss: 0.0121Restoring model weights from the end of the best epoch.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0121 - val_loss: 0.0152\r\n",
      "Epoch 00033: early stopping\r\n",
      "Epoch 1/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.2475 - val_loss: 0.0244\r\n",
      "Epoch 2/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0225 - val_loss: 0.0191\r\n",
      "Epoch 3/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0195 - val_loss: 0.0178\r\n",
      "Epoch 4/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0184 - val_loss: 0.0172\r\n",
      "Epoch 5/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0176 - val_loss: 0.0166\r\n",
      "Epoch 6/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0169 - val_loss: 0.0166\r\n",
      "Epoch 7/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0165 - val_loss: 0.0160\r\n",
      "Epoch 8/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0161 - val_loss: 0.0157\r\n",
      "Epoch 9/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0157 - val_loss: 0.0156\r\n",
      "Epoch 10/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0156 - val_loss: 0.0155\r\n",
      "Epoch 11/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0150 - val_loss: 0.0154\r\n",
      "Epoch 12/500\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.0146 - val_loss: 0.0155\r\n",
      "Epoch 13/500\r\n",
      "298/298 [==============================] - 3s 11ms/step - loss: 0.0143 - val_loss: 0.0154\r\n",
      "Epoch 14/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0138 - val_loss: 0.0152\r\n",
      "Epoch 15/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0135 - val_loss: 0.0152\r\n",
      "Epoch 16/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0131 - val_loss: 0.0152\r\n",
      "Epoch 17/500\r\n",
      "293/298 [============================>.] - ETA: 0s - loss: 0.0127\r\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0127 - val_loss: 0.0153\r\n",
      "Epoch 18/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0117 - val_loss: 0.0151\r\n",
      "Epoch 19/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0113 - val_loss: 0.0150\r\n",
      "Epoch 20/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0111 - val_loss: 0.0150\r\n",
      "Epoch 21/500\r\n",
      "295/298 [============================>.] - ETA: 0s - loss: 0.0109\r\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0110 - val_loss: 0.0150\r\n",
      "Epoch 22/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0108 - val_loss: 0.0150\r\n",
      "Epoch 23/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0107 - val_loss: 0.0150\r\n",
      "Epoch 24/500\r\n",
      "293/298 [============================>.] - ETA: 0s - loss: 0.0107\r\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0107 - val_loss: 0.0150\r\n",
      "Epoch 25/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0107 - val_loss: 0.0150\r\n",
      "Epoch 26/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0108 - val_loss: 0.0150\r\n",
      "Epoch 27/500\r\n",
      "292/298 [============================>.] - ETA: 0s - loss: 0.0107\r\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0107 - val_loss: 0.0150\r\n",
      "Epoch 28/500\r\n",
      "298/298 [==============================] - 3s 8ms/step - loss: 0.0108 - val_loss: 0.0150\r\n",
      "Epoch 29/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0108 - val_loss: 0.0150\r\n",
      "Epoch 30/500\r\n",
      "290/298 [============================>.] - ETA: 0s - loss: 0.0108\r\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0108 - val_loss: 0.0150\r\n",
      "Epoch 31/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0109 - val_loss: 0.0150\r\n",
      "Epoch 32/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0109 - val_loss: 0.0150\r\n",
      "Epoch 33/500\r\n",
      "291/298 [============================>.] - ETA: 0s - loss: 0.0110\r\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0110 - val_loss: 0.0150\r\n",
      "Epoch 34/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0110 - val_loss: 0.0150\r\n",
      "Epoch 35/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0110 - val_loss: 0.0150\r\n",
      "Epoch 36/500\r\n",
      "293/298 [============================>.] - ETA: 0s - loss: 0.0110\r\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0110 - val_loss: 0.0150\r\n",
      "Epoch 37/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0111 - val_loss: 0.0151\r\n",
      "Epoch 38/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0111 - val_loss: 0.0151\r\n",
      "Epoch 39/500\r\n",
      "298/298 [==============================] - ETA: 0s - loss: 0.0112Restoring model weights from the end of the best epoch.\r\n",
      "\r\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0112 - val_loss: 0.0151\r\n",
      "Epoch 00039: early stopping\r\n",
      " 67%|█████████████████████████████▎              | 2/3 [14:50<07:30, 450.59s/it]/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass shuffle=True, random_state=2 as keyword args. From version 0.25 passing these as positional arguments will result in an error\r\n",
      "  FutureWarning)\r\n",
      "Epoch 1/500\r\n",
      "298/298 [==============================] - 4s 14ms/step - loss: 0.2477 - val_loss: 0.0250\r\n",
      "Epoch 2/500\r\n",
      "298/298 [==============================] - 3s 11ms/step - loss: 0.0224 - val_loss: 0.0190\r\n",
      "Epoch 3/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0194 - val_loss: 0.0180\r\n",
      "Epoch 4/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0183 - val_loss: 0.0172\r\n",
      "Epoch 5/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0176 - val_loss: 0.0167\r\n",
      "Epoch 6/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0169 - val_loss: 0.0165\r\n",
      "Epoch 7/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0164 - val_loss: 0.0161\r\n",
      "Epoch 8/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0163 - val_loss: 0.0160\r\n",
      "Epoch 9/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0158 - val_loss: 0.0158\r\n",
      "Epoch 10/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0153 - val_loss: 0.0155\r\n",
      "Epoch 11/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0150 - val_loss: 0.0155\r\n",
      "Epoch 12/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0146 - val_loss: 0.0153\r\n",
      "Epoch 13/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0142 - val_loss: 0.0153\r\n",
      "Epoch 14/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0139 - val_loss: 0.0152\r\n",
      "Epoch 15/500\r\n",
      "298/298 [==============================] - ETA: 0s - loss: 0.0135\r\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0135 - val_loss: 0.0152\r\n",
      "Epoch 16/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0124 - val_loss: 0.0150\r\n",
      "Epoch 17/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0122 - val_loss: 0.0150\r\n",
      "Epoch 18/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0120 - val_loss: 0.0150\r\n",
      "Epoch 19/500\r\n",
      "292/298 [============================>.] - ETA: 0s - loss: 0.0118\r\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0118 - val_loss: 0.0150\r\n",
      "Epoch 20/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0116 - val_loss: 0.0150\r\n",
      "Epoch 21/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0116 - val_loss: 0.0150\r\n",
      "Epoch 22/500\r\n",
      "296/298 [============================>.] - ETA: 0s - loss: 0.0116\r\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0117 - val_loss: 0.0149\r\n",
      "Epoch 23/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0116 - val_loss: 0.0149\r\n",
      "Epoch 24/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0116 - val_loss: 0.0149\r\n",
      "Epoch 25/500\r\n",
      "297/298 [============================>.] - ETA: 0s - loss: 0.0117\r\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0117 - val_loss: 0.0149\r\n",
      "Epoch 26/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0117 - val_loss: 0.0150\r\n",
      "Epoch 27/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0117 - val_loss: 0.0150\r\n",
      "Epoch 28/500\r\n",
      "290/298 [============================>.] - ETA: 0s - loss: 0.0117\r\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0117 - val_loss: 0.0150\r\n",
      "Epoch 29/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0117 - val_loss: 0.0150\r\n",
      "Epoch 30/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0118 - val_loss: 0.0150\r\n",
      "Epoch 31/500\r\n",
      "296/298 [============================>.] - ETA: 0s - loss: 0.0118\r\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.0118 - val_loss: 0.0150\r\n",
      "Epoch 32/500\r\n",
      "298/298 [==============================] - 3s 11ms/step - loss: 0.0119 - val_loss: 0.0150\r\n",
      "Epoch 33/500\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.0119 - val_loss: 0.0150\r\n",
      "Epoch 34/500\r\n",
      "293/298 [============================>.] - ETA: 0s - loss: 0.0119Restoring model weights from the end of the best epoch.\r\n",
      "\r\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0119 - val_loss: 0.0151\r\n",
      "Epoch 00034: early stopping\r\n",
      "Epoch 1/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.2451 - val_loss: 0.0248\r\n",
      "Epoch 2/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0227 - val_loss: 0.0190\r\n",
      "Epoch 3/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0195 - val_loss: 0.0178\r\n",
      "Epoch 4/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0183 - val_loss: 0.0172\r\n",
      "Epoch 5/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0176 - val_loss: 0.0167\r\n",
      "Epoch 6/500\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.0169 - val_loss: 0.0163\r\n",
      "Epoch 7/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0165 - val_loss: 0.0160\r\n",
      "Epoch 8/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0161 - val_loss: 0.0159\r\n",
      "Epoch 9/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0157 - val_loss: 0.0156\r\n",
      "Epoch 10/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0154 - val_loss: 0.0157\r\n",
      "Epoch 11/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0150 - val_loss: 0.0154\r\n",
      "Epoch 12/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0146 - val_loss: 0.0153\r\n",
      "Epoch 13/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0143 - val_loss: 0.0153\r\n",
      "Epoch 14/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0139 - val_loss: 0.0152\r\n",
      "Epoch 15/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0135 - val_loss: 0.0152\r\n",
      "Epoch 16/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0131 - val_loss: 0.0152\r\n",
      "Epoch 17/500\r\n",
      "292/298 [============================>.] - ETA: 0s - loss: 0.0127\r\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0127 - val_loss: 0.0153\r\n",
      "Epoch 18/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0116 - val_loss: 0.0151\r\n",
      "Epoch 19/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0113 - val_loss: 0.0151\r\n",
      "Epoch 20/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0112 - val_loss: 0.0150\r\n",
      "Epoch 21/500\r\n",
      "298/298 [==============================] - 3s 8ms/step - loss: 0.0110 - val_loss: 0.0151\r\n",
      "Epoch 22/500\r\n",
      "298/298 [==============================] - ETA: 0s - loss: 0.0108\r\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0108 - val_loss: 0.0151\r\n",
      "Epoch 23/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0106 - val_loss: 0.0151\r\n",
      "Epoch 24/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0106 - val_loss: 0.0150\r\n",
      "Epoch 25/500\r\n",
      "298/298 [==============================] - ETA: 0s - loss: 0.0106\r\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.0106 - val_loss: 0.0150\r\n",
      "Epoch 26/500\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.0106 - val_loss: 0.0150\r\n",
      "Epoch 27/500\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.0106 - val_loss: 0.0150\r\n",
      "Epoch 28/500\r\n",
      "294/298 [============================>.] - ETA: 0s - loss: 0.0106\r\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0106 - val_loss: 0.0150\r\n",
      "Epoch 29/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0106 - val_loss: 0.0150\r\n",
      "Epoch 30/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0107 - val_loss: 0.0150\r\n",
      "Epoch 31/500\r\n",
      "294/298 [============================>.] - ETA: 0s - loss: 0.0107\r\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0107 - val_loss: 0.0150\r\n",
      "Epoch 32/500\r\n",
      "298/298 [==============================] - 3s 8ms/step - loss: 0.0107 - val_loss: 0.0150\r\n",
      "Epoch 33/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0107 - val_loss: 0.0150\r\n",
      "Epoch 34/500\r\n",
      "293/298 [============================>.] - ETA: 0s - loss: 0.0108\r\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0108 - val_loss: 0.0150\r\n",
      "Epoch 35/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0108 - val_loss: 0.0150\r\n",
      "Epoch 36/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0109 - val_loss: 0.0150\r\n",
      "Epoch 37/500\r\n",
      "290/298 [============================>.] - ETA: 0s - loss: 0.0109\r\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0109 - val_loss: 0.0151\r\n",
      "Epoch 38/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0110 - val_loss: 0.0151\r\n",
      "Epoch 39/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0110 - val_loss: 0.0151\r\n",
      "Epoch 40/500\r\n",
      "296/298 [============================>.] - ETA: 0s - loss: 0.0111\r\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0111 - val_loss: 0.0151\r\n",
      "Epoch 41/500\r\n",
      "297/298 [============================>.] - ETA: 0s - loss: 0.0111Restoring model weights from the end of the best epoch.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0111 - val_loss: 0.0151\r\n",
      "Epoch 00041: early stopping\r\n",
      "Epoch 1/500\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.2462 - val_loss: 0.0266\r\n",
      "Epoch 2/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0224 - val_loss: 0.0192\r\n",
      "Epoch 3/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0194 - val_loss: 0.0180\r\n",
      "Epoch 4/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0183 - val_loss: 0.0173\r\n",
      "Epoch 5/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0175 - val_loss: 0.0169\r\n",
      "Epoch 6/500\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.0168 - val_loss: 0.0163\r\n",
      "Epoch 7/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0165 - val_loss: 0.0162\r\n",
      "Epoch 8/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0160 - val_loss: 0.0161\r\n",
      "Epoch 9/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0157 - val_loss: 0.0159\r\n",
      "Epoch 10/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0152 - val_loss: 0.0158\r\n",
      "Epoch 11/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0149 - val_loss: 0.0157\r\n",
      "Epoch 12/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0146 - val_loss: 0.0156\r\n",
      "Epoch 13/500\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.0141 - val_loss: 0.0155\r\n",
      "Epoch 14/500\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.0138 - val_loss: 0.0156\r\n",
      "Epoch 15/500\r\n",
      "298/298 [==============================] - 4s 13ms/step - loss: 0.0136 - val_loss: 0.0156\r\n",
      "Epoch 16/500\r\n",
      "298/298 [==============================] - ETA: 0s - loss: 0.0130\r\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\r\n",
      "298/298 [==============================] - 3s 8ms/step - loss: 0.0130 - val_loss: 0.0154\r\n",
      "Epoch 17/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0120 - val_loss: 0.0153\r\n",
      "Epoch 18/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0117 - val_loss: 0.0153\r\n",
      "Epoch 19/500\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.0115 - val_loss: 0.0153\r\n",
      "Epoch 20/500\r\n",
      "297/298 [============================>.] - ETA: 0s - loss: 0.0113\r\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0113 - val_loss: 0.0153\r\n",
      "Epoch 21/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0112 - val_loss: 0.0152\r\n",
      "Epoch 22/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0112 - val_loss: 0.0152\r\n",
      "Epoch 23/500\r\n",
      "291/298 [============================>.] - ETA: 0s - loss: 0.0112\r\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0112 - val_loss: 0.0152\r\n",
      "Epoch 24/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0112 - val_loss: 0.0152\r\n",
      "Epoch 25/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0112 - val_loss: 0.0152\r\n",
      "Epoch 26/500\r\n",
      "292/298 [============================>.] - ETA: 0s - loss: 0.0111\r\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0111 - val_loss: 0.0152\r\n",
      "Epoch 27/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0112 - val_loss: 0.0152\r\n",
      "Epoch 28/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0112 - val_loss: 0.0152\r\n",
      "Epoch 29/500\r\n",
      "298/298 [==============================] - ETA: 0s - loss: 0.0113\r\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0113 - val_loss: 0.0152\r\n",
      "Epoch 30/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0113 - val_loss: 0.0152\r\n",
      "Epoch 31/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0113 - val_loss: 0.0152\r\n",
      "Epoch 32/500\r\n",
      "297/298 [============================>.] - ETA: 0s - loss: 0.0113\r\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0113 - val_loss: 0.0152\r\n",
      "Epoch 33/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0114 - val_loss: 0.0152\r\n",
      "Epoch 34/500\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.0114 - val_loss: 0.0152\r\n",
      "Epoch 35/500\r\n",
      "295/298 [============================>.] - ETA: 0s - loss: 0.0115\r\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0115 - val_loss: 0.0152\r\n",
      "Epoch 36/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0115 - val_loss: 0.0153\r\n",
      "Epoch 37/500\r\n",
      "291/298 [============================>.] - ETA: 0s - loss: 0.0115Restoring model weights from the end of the best epoch.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0115 - val_loss: 0.0153\r\n",
      "Epoch 00037: early stopping\r\n",
      "Epoch 1/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.2462 - val_loss: 0.0260\r\n",
      "Epoch 2/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0225 - val_loss: 0.0191\r\n",
      "Epoch 3/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0194 - val_loss: 0.0178\r\n",
      "Epoch 4/500\r\n",
      "298/298 [==============================] - 3s 11ms/step - loss: 0.0184 - val_loss: 0.0173\r\n",
      "Epoch 5/500\r\n",
      "298/298 [==============================] - 3s 11ms/step - loss: 0.0176 - val_loss: 0.0167\r\n",
      "Epoch 6/500\r\n",
      "298/298 [==============================] - 3s 11ms/step - loss: 0.0170 - val_loss: 0.0164\r\n",
      "Epoch 7/500\r\n",
      "298/298 [==============================] - 4s 12ms/step - loss: 0.0165 - val_loss: 0.0161\r\n",
      "Epoch 8/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0160 - val_loss: 0.0159\r\n",
      "Epoch 9/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0157 - val_loss: 0.0157\r\n",
      "Epoch 10/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0153 - val_loss: 0.0156\r\n",
      "Epoch 11/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0150 - val_loss: 0.0154\r\n",
      "Epoch 12/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0147 - val_loss: 0.0154\r\n",
      "Epoch 13/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0143 - val_loss: 0.0154\r\n",
      "Epoch 14/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0139 - val_loss: 0.0153\r\n",
      "Epoch 15/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0135 - val_loss: 0.0153\r\n",
      "Epoch 16/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0131 - val_loss: 0.0153\r\n",
      "Epoch 17/500\r\n",
      "293/298 [============================>.] - ETA: 0s - loss: 0.0127\r\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0128 - val_loss: 0.0154\r\n",
      "Epoch 18/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0117 - val_loss: 0.0151\r\n",
      "Epoch 19/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0114 - val_loss: 0.0151\r\n",
      "Epoch 20/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0112 - val_loss: 0.0151\r\n",
      "Epoch 21/500\r\n",
      "297/298 [============================>.] - ETA: 0s - loss: 0.0110\r\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0110 - val_loss: 0.0151\r\n",
      "Epoch 22/500\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.0108 - val_loss: 0.0151\r\n",
      "Epoch 23/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0108 - val_loss: 0.0151\r\n",
      "Epoch 24/500\r\n",
      "296/298 [============================>.] - ETA: 0s - loss: 0.0108\r\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0108 - val_loss: 0.0151\r\n",
      "Epoch 25/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0108 - val_loss: 0.0151\r\n",
      "Epoch 26/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0108 - val_loss: 0.0151\r\n",
      "Epoch 27/500\r\n",
      "294/298 [============================>.] - ETA: 0s - loss: 0.0108\r\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0108 - val_loss: 0.0151\r\n",
      "Epoch 28/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0108 - val_loss: 0.0151\r\n",
      "Epoch 29/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0108 - val_loss: 0.0151\r\n",
      "Epoch 30/500\r\n",
      "291/298 [============================>.] - ETA: 0s - loss: 0.0109\r\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0109 - val_loss: 0.0150\r\n",
      "Epoch 31/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0109 - val_loss: 0.0151\r\n",
      "Epoch 32/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0109 - val_loss: 0.0151\r\n",
      "Epoch 33/500\r\n",
      "294/298 [============================>.] - ETA: 0s - loss: 0.0109\r\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0109 - val_loss: 0.0151\r\n",
      "Epoch 34/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0110 - val_loss: 0.0151\r\n",
      "Epoch 35/500\r\n",
      "298/298 [==============================] - 3s 11ms/step - loss: 0.0110 - val_loss: 0.0151\r\n",
      "Epoch 36/500\r\n",
      "296/298 [============================>.] - ETA: 0s - loss: 0.0111\r\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\r\n",
      "298/298 [==============================] - 4s 13ms/step - loss: 0.0111 - val_loss: 0.0151\r\n",
      "Epoch 37/500\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.0111 - val_loss: 0.0151\r\n",
      "Epoch 38/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0112 - val_loss: 0.0151\r\n",
      "Epoch 39/500\r\n",
      "293/298 [============================>.] - ETA: 0s - loss: 0.0112\r\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-11.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0112 - val_loss: 0.0152\r\n",
      "Epoch 40/500\r\n",
      "292/298 [============================>.] - ETA: 0s - loss: 0.0113Restoring model weights from the end of the best epoch.\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0113 - val_loss: 0.0152\r\n",
      "Epoch 00040: early stopping\r\n",
      "Epoch 1/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.2460 - val_loss: 0.0256\r\n",
      "Epoch 2/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0224 - val_loss: 0.0189\r\n",
      "Epoch 3/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0193 - val_loss: 0.0178\r\n",
      "Epoch 4/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0181 - val_loss: 0.0171\r\n",
      "Epoch 5/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0174 - val_loss: 0.0168\r\n",
      "Epoch 6/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0168 - val_loss: 0.0165\r\n",
      "Epoch 7/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0164 - val_loss: 0.0161\r\n",
      "Epoch 8/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0160 - val_loss: 0.0160\r\n",
      "Epoch 9/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0155 - val_loss: 0.0160\r\n",
      "Epoch 10/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0152 - val_loss: 0.0157\r\n",
      "Epoch 11/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0149 - val_loss: 0.0156\r\n",
      "Epoch 12/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0145 - val_loss: 0.0156\r\n",
      "Epoch 13/500\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.0142 - val_loss: 0.0155\r\n",
      "Epoch 14/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0138 - val_loss: 0.0154\r\n",
      "Epoch 15/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0134 - val_loss: 0.0154\r\n",
      "Epoch 16/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0130 - val_loss: 0.0153\r\n",
      "Epoch 17/500\r\n",
      "292/298 [============================>.] - ETA: 0s - loss: 0.0126\r\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0126 - val_loss: 0.0154\r\n",
      "Epoch 18/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0114 - val_loss: 0.0153\r\n",
      "Epoch 19/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0112 - val_loss: 0.0152\r\n",
      "Epoch 20/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0109 - val_loss: 0.0152\r\n",
      "Epoch 21/500\r\n",
      "294/298 [============================>.] - ETA: 0s - loss: 0.0107\r\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0107 - val_loss: 0.0152\r\n",
      "Epoch 22/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0105 - val_loss: 0.0152\r\n",
      "Epoch 23/500\r\n",
      "298/298 [==============================] - 4s 12ms/step - loss: 0.0105 - val_loss: 0.0152\r\n",
      "Epoch 24/500\r\n",
      "296/298 [============================>.] - ETA: 0s - loss: 0.0105\r\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.0105 - val_loss: 0.0152\r\n",
      "Epoch 25/500\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.0105 - val_loss: 0.0152\r\n",
      "Epoch 26/500\r\n",
      "298/298 [==============================] - 3s 11ms/step - loss: 0.0105 - val_loss: 0.0152\r\n",
      "Epoch 27/500\r\n",
      "297/298 [============================>.] - ETA: 0s - loss: 0.0105\r\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0105 - val_loss: 0.0152\r\n",
      "Epoch 28/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0106 - val_loss: 0.0152\r\n",
      "Epoch 29/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0106 - val_loss: 0.0152\r\n",
      "Epoch 30/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0106 - val_loss: 0.0152\r\n",
      "Epoch 31/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0107 - val_loss: 0.0152\r\n",
      "Epoch 32/500\r\n",
      "295/298 [============================>.] - ETA: 0s - loss: 0.0107\r\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0107 - val_loss: 0.0152\r\n",
      "Epoch 33/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0107 - val_loss: 0.0152\r\n",
      "Epoch 34/500\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0108 - val_loss: 0.0152\r\n",
      "Epoch 35/500\r\n",
      "297/298 [============================>.] - ETA: 0s - loss: 0.0109\r\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\r\n",
      "298/298 [==============================] - 3s 10ms/step - loss: 0.0109 - val_loss: 0.0152\r\n",
      "Epoch 36/500\r\n",
      "298/298 [==============================] - 3s 9ms/step - loss: 0.0108 - val_loss: 0.0152\r\n",
      "Epoch 37/500\r\n",
      "298/298 [==============================] - 2s 8ms/step - loss: 0.0109 - val_loss: 0.0152\r\n",
      "Epoch 38/500\r\n",
      "297/298 [============================>.] - ETA: 0s - loss: 0.0109\r\n",
      "Epoch 00038: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-10.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0109 - val_loss: 0.0152\r\n",
      "Epoch 39/500\r\n",
      "294/298 [============================>.] - ETA: 0s - loss: 0.0110Restoring model weights from the end of the best epoch.\r\n",
      "298/298 [==============================] - 2s 7ms/step - loss: 0.0110 - val_loss: 0.0153\r\n",
      "Epoch 00039: early stopping\r\n",
      "100%|████████████████████████████████████████████| 3/3 [22:43<00:00, 454.63s/it]\r\n",
      "NN OOF before postprocessing: 0.014769\r\n",
      "NN OOF after postprocessing: 0.014629\r\n"
     ]
    }
   ],
   "source": [
    "! python inference.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 1413.46769,
   "end_time": "2020-11-28T23:42:00.770374",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-28T23:18:27.302684",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
